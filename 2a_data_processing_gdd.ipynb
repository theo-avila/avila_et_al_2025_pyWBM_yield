{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70db2915-0d9a-4789-a959-d306cc85cc39",
   "metadata": {},
   "source": [
    "# 2a processing\n",
    "- this code downloads and merges nldas for growing degree days, extreme degree days calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5c768-85fe-482e-8857-cff03d7dfaa5",
   "metadata": {},
   "source": [
    "## downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f014be-7efe-44d3-bde8-ad12c15e894c",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedc61c4-8c14-4c29-9de5-4258c9a64c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import dask\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636481c-b9b5-4758-b6cc-c1dfae523351",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa162299-3602-4aef-a8e8-9e6fd33bb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadData(url, output_dir, session):\n",
    "    '''\n",
    "    Given a URL and an authenticated session, this function downloads data from\n",
    "    NASA Earthdata and saves it in the specified output directory.\n",
    "    \n",
    "    inputs:\n",
    "      url: a string representing the file URL.\n",
    "      output_dir: the directory where the file should be saved.\n",
    "      session: an authenticated requests.Session() object.\n",
    "    \n",
    "    returns: nothing\n",
    "    '''\n",
    "    response = session.get(url, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        cd = response.headers.get(\"content-disposition\")\n",
    "        if cd:\n",
    "            fname_match = re.findall('filename=\"?([^\";]+)\"?', cd)\n",
    "            filename = fname_match[0] if fname_match else url.split(\"/\")[-1]\n",
    "        else:\n",
    "            filename = url.split(\"/\")[-1]\n",
    "        \n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "    else:\n",
    "        raise Exception(f\"Error downloading {url}: HTTP {response.status_code}\")\n",
    "    return filename\n",
    "    \n",
    "def aggregate_day_files(date_str, output_dir):\n",
    "    '''\n",
    "    inputs \n",
    "    yyyymmdd as datestr\n",
    "    location for files to be saved as outputdir\n",
    "    '''\n",
    "    pattern = os.path.join(output_dir, f\"{output_dir}/NLDAS_MOS0125_H.A{date_str}.*.grb.SUB.nc4\")\n",
    "    file_list = sorted(glob.glob(pattern))\n",
    "\n",
    "    if not file_list:\n",
    "        print(f\"No files found for date {date_str}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        ds = xr.open_mfdataset(file_list, combine='by_coords')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error opening files for {date_str}: {e}\")\n",
    "        return None\n",
    "        \n",
    "    ds_daily = ds.resample(time='1D').mean().sel(depth=100.0)\n",
    "\n",
    "    daily_file = os.path.join(output_dir, f\"{output_dir}/NLDAS_MOS0125_H.A{date_str}_daily_100cm.nc\")\n",
    "    ds_daily.to_netcdf(daily_file)\n",
    "    \n",
    "    for file_to_remove in glob.glob(pattern):\n",
    "        os.remove(file_to_remove)\n",
    "    \n",
    "    \n",
    "def urls_list():\n",
    "    # Retrieve credentials from environment variables.\n",
    "    username = os.environ.get(\"earthnasa_user\")\n",
    "    password = os.environ.get(\"earthnasa_pass\")\n",
    "    \n",
    "    if not username or not password:\n",
    "        raise Exception(\"Missing credentials. Please set earthnasa_user and earthnasa_pass in your environment.\")\n",
    "\n",
    "    url_file = \"/storage/home/cta5244/work/pyWBM_yield_data/hydro_models/subset_NLDAS_MOS0125_H_002_20250225_212838_.txt\"\n",
    "    output_dir = \"/storage/home/cta5244/work/pyWBM_yield_data/hydro_models/MOSAIC/daily_soil100cm\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    session = requests.Session()\n",
    "    session.auth = (username, password)\n",
    "    \n",
    "    with open(url_file, \"r\") as f:\n",
    "        urls = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "    for url in urls[22:25]:\n",
    "        try:\n",
    "            file_path = downloadData(url, output_dir, session)\n",
    "            \n",
    "            match = re.search(r\"NLDAS_MOS0125_H\\.A(\\d{8})\\.(\\d{4})\\.002\\.grb\\.SUB\", file_path)\n",
    "            if match:\n",
    "                date_str = match.group(1)  \n",
    "                hour_str = match.group(2)\n",
    "                \n",
    "                if hour_str.startswith(\"23\"):\n",
    "                    aggregate_day_files(date_str, output_dir)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    \n",
    "urls_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47621d92-e4f2-4b58-bf44-fe9bd66c654b",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21bb118-309e-400e-83bb-da1222ebd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "output_dir = \"/storage/home/cta5244/work/pyWBM_yield_data/hydro_models/MOSAIC/daily_soil100cm\"\n",
    "base_url = \"https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/NLDAS_MOS0125_H.002\"\n",
    "specific_model_path = \"NLDAS_MOS0125_H.A\"\n",
    "file_type = \"grb\"\n",
    "\n",
    "start_year = 1979\n",
    "end_year = 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec5178-3ffb-40a8-88a4-c359e7580d58",
   "metadata": {},
   "source": [
    "### dask implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff72b7ed-6672-497f-be1e-bfcc3b0011b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # account=\"pches\",\n",
    "    account=\"open\",\n",
    "    cores=1,\n",
    "    memory=\"2GiB\",\n",
    "    walltime=\"24:00:00\",\n",
    ")\n",
    "\n",
    "cluster.scale(jobs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39207442-ef3f-4a36-a51a-6b5ac8209064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99caa6e-3206-4864-851b-4cbe0111b38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fc702-1ac4-4806-af8b-791457d07bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for year in np.arange(start_year, end_year, 1):\n",
    "    out = dask.delayed(singleYearUrl)(year=year)\n",
    "    results.append(out)\n",
    "    \n",
    "results = dask.compute(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f2836-77b5-453e-b0d8-4510252fece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
