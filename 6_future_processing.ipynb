{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719bba6b-a7f2-4089-973f-bde148f49361",
   "metadata": {},
   "source": [
    "# pyWBM Future Cleaning\n",
    "- This code is used for cleaning and processing future pyWBM & LOCA2 projections\n",
    "- Allows us to take this data (panel) and use our coefficients from notebook 5 for future projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f75dbe-adf2-4dad-8cd7-cfc6749b9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dask\n",
    "import os\n",
    "import glob as glob\n",
    "import cftime \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c55ca-fb50-4960-9c31-1d4e0711952b",
   "metadata": {},
   "source": [
    "## Growing degree days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb4bf94-f2ec-42c1-9f02-f57278914117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_2a import degreeDays, yearlyCalculationSum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9576b-2d86-4686-806c-b1fb9ca2bd68",
   "metadata": {},
   "source": [
    "### Filepaths & Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276823da-0de2-4fcc-96c3-1accebf17f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cmip6 model names used in loca2, the full path for reference = \"/storage/group/pches/default/public/LOCA2/ACCESS-CM2/0p0625deg/r1i1p1f1/ssp245/tasmin\"\n",
    "base_loca_paths_for_models = \"/storage/group/pches/default/public/LOCA2/\"\n",
    "models = sorted(glob.glob(f\"{base_loca_paths_for_models}*\"))\n",
    "model_names = [os.path.basename(m) for m in models][:-2]\n",
    "\n",
    "# ssp scenarios used in pyWBM are 245 and 370\n",
    "ssps = [\"245\", \"370\"]\n",
    "\n",
    "# intitalizataions, only using r1i1p1f1 for now, some runs have more than 1 init\n",
    "initializations = [\"r1i1p1f1\"]\n",
    "\n",
    "# loca2 is in chunks of ~30 years \n",
    "time_frames = [\"2015-2044\", \"2045-2074\", \"2075-2100\"]\n",
    "\n",
    "nldas_lsm = \"VIC\"\n",
    "\n",
    "# this is the soil_moiture base path\n",
    "pyWBM_file_path_base = \"/storage/group/pches/default/users/dcl5300/wbm_soilM_uc_2024_DATA/projections/eCONUS/out/LOCA2\"\n",
    "\n",
    "# soil moisture historical normal \n",
    "soil_moisture_normal_file_path = f\"/storage/home/cta5244/work/avila_et_al_2025_pyWBM_yield/data/{nldas_lsm}_seasonal_average_alltime_average_soilmoisture.nc\"\n",
    "\n",
    "# some arbritrary pyWBM run for regridding\n",
    "arbritrary_pyWBM_run = f'/storage/group/pches/default/users/dcl5300/wbm_soilM_uc_2024_DATA/projections/eCONUS/out/LOCA2/ACCESS-CM2_r1i1p1f1_ssp245_VIC_kge.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb81309e-69eb-48a8-a211-1489ee06384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 year error, pass this year Index 0 is out of bounds for axis 0 with size 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x150d2b554dc0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x150d2b554dc0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x150d2b554dc0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# each loca2 file is 10GB (large)\n",
    "if __name__ == \"__main__\":\n",
    "    # first lets get some base pyWBM run, & base historical normal to use for future regridding\n",
    "    # by getting ds_soil_normal_on_wbm_grid we can use it without issue for any pyWBM anomaly vs the historical time frame\n",
    "    ds_soilpyWBM_regrid = (xr.open_dataset(arbritrary_pyWBM_run)).chunk({\"time\": 1, \"lon\":100, \"lat\":100})\n",
    "    ds_soil_normal = xr.open_dataset(soil_moisture_normal_file_path).SoilM_0_100cm\n",
    "    ds_soil_normal_on_wbm_grid = ds_soil_normal.interp(\n",
    "        lat=ds_soilpyWBM_regrid.lat,\n",
    "        lon=ds_soilpyWBM_regrid.lon,\n",
    "        method=\"linear\"  # or \"nearest\" if you prefer\n",
    "    ).chunk()\n",
    "    \n",
    "    for model_name_i in model_names[:1]:\n",
    "        for initialization_i in initializations:\n",
    "            for ssp_i in ssps[:1]:\n",
    "                for time_frame_i in time_frames:\n",
    "                    # tmax file\n",
    "                    file_path_i_tmax = f\"{base_loca_paths_for_models}{model_name_i}/0p0625deg/{initialization_i}/ssp{ssp_i}/tasmax\"\n",
    "                    file_name_i_tmax = f\"tasmax.{model_name_i}.ssp{ssp_i}.{initialization_i}.{time_frame_i}.LOCA_16thdeg_v20220413.nc\"\n",
    "                    # tmin file\n",
    "                    file_path_i_tmin = f\"{base_loca_paths_for_models}{model_name_i}/0p0625deg/{initialization_i}/ssp{ssp_i}/tasmin\"\n",
    "                    file_name_i_tmin = f\"tasmin.{model_name_i}.ssp{ssp_i}.{initialization_i}.{time_frame_i}.LOCA_16thdeg_v20220413.nc\"\n",
    "                    \n",
    "                    # combing them for usage in degree day calculation\n",
    "                    try:\n",
    "                        LOCA2_tmax = xr.open_dataset(f\"{file_path_i_tmax}/{file_name_i_tmax}\", chunks='auto').rename({\"tasmax\": \"tmax\"})\n",
    "                        LOCA2_tmin = xr.open_dataset(f\"{file_path_i_tmin}/{file_name_i_tmin}\", chunks='auto').rename({\"tasmin\": \"tmin\"})\n",
    "                        LOCA2_combined = xr.merge([LOCA2_tmax, LOCA2_tmin])\n",
    "                        \n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"Issue with file location, skipping {file_path_i_tmax}/{file_name_i_tmax} or {file_path_i_tmin}/{file_name_i_tmin}\")\n",
    "                        break\n",
    "\n",
    "                    # this inputs some big daily chunked dataset, and outputs the gdd & edd binned using pyWBM futures\n",
    "                    results_season_and_soilm = []\n",
    "                    start_year = int(LOCA2_combined.time.dt.year.values[0])\n",
    "                    end_year = int(LOCA2_combined.time.dt.year.values[-1])\n",
    "                    for year in range(start_year, end_year + 1)[:10]:\n",
    "                        # gives single year slice, and growing degree days '\n",
    "                        ds_slice = LOCA2_combined.sel(time=slice(f\"{year}-04-01\", f\"{year}-09-30\")).chunk({\"time\": 1})\n",
    "                        ds_slice = ds_slice.assign_coords(\n",
    "                            lon=((ds_slice.lon + 180) % 360) - 180\n",
    "                        ).sortby(\"lon\")\n",
    "                        \n",
    "                        # keep ds slice for a land mask pre-interpolation to avoid pulling ocean values into linear interpolation\n",
    "                        land_mask = ds_slice.tmax.isel(time=0).notnull().copy(deep=True)\n",
    "\n",
    "                        # then calculate degree days\n",
    "                        gdd_future = degreeDays(ds_slice, 'gdd')\n",
    "                        gdd_future_sum = gdd_future.groupby(\"time.year\").sum(\"time\").reset_coords(drop=True) # this is seasonal growing degree day spatially, temporally for combination of i of input parameters\n",
    "                        \n",
    "                        gdd_future_mask = gdd_future_sum.where(land_mask)  # mask applied on the cleaned grid\n",
    "                        gdd_future_regrid = gdd_future_mask.interp(\n",
    "                            lat=ds_soilpyWBM_regrid.lat, \n",
    "                            lon=ds_soilpyWBM_regrid.lon, \n",
    "                            method=\"linear\",\n",
    "                            kwargs={\"fill_value\": np.nan}\n",
    "                        ).chunk()                          # this interpolates \n",
    "                        \n",
    "                        # now looking at edd, but important to bin for compound extremes, everything on pyWBM grid which is 1/8 as opposed to LOCA2s 1/16edd_future\n",
    "                        edd_future = degreeDays(ds_slice, 'edd')\n",
    "                        edd_future_mask = edd_future.where(land_mask)\n",
    "                        edd_future_regrid = edd_future_mask.interp(\n",
    "                                lat=ds_soilpyWBM_regrid.lat, \n",
    "                                lon=ds_soilpyWBM_regrid.lon, \n",
    "                                method=\"linear\",  # or \"linear\", depending on your needs\n",
    "                                kwargs={\"fill_value\": np.nan}\n",
    "                        ).chunk()\n",
    "                        \n",
    "                        # getting compound extreme data from pyWBM large ensemble\n",
    "                        pywbm_combinations = sorted(glob.glob(f\"{pyWBM_file_path_base}/{model_name_i}_{initialization_i}_ssp{ssp_i}_{nldas_lsm}*\"))\n",
    "                        ds_soilpyWBM_initial_chunk_open = (xr.open_dataset(pywbm_combinations[0])).chunk({\"lon\":100, \"lat\":100})\n",
    "                        # everything above works as expecte but the next line causes issues \n",
    "                        ds_soilpyWBM_initial_chunk_open['time'] = ds_soilpyWBM_initial_chunk_open.indexes['time'].to_datetimeindex()\n",
    "                        ds_soilpyWBM_initial_chunk_single_year = ds_soilpyWBM_initial_chunk_open.sel(time=slice(f\"{year}-04-01\", f\"{year}-09-30\"))\n",
    "                        \n",
    "                        # mask out west coast so LOCA2 only exists in pyWBM space\n",
    "                        ds_soil_normal_on_wbm_grid_masked = ds_soil_normal_on_wbm_grid.where(~np.isnan(ds_soilpyWBM_initial_chunk_single_year))\n",
    "                        ds_soil_normal_on_wbm_grid_masked = ds_soil_normal_on_wbm_grid_masked.transpose('time', 'lat', 'lon')\n",
    "                        deviation_from_normal = ds_soilpyWBM_initial_chunk_single_year - ds_soil_normal_on_wbm_grid_masked.soilMoist\n",
    "                        \n",
    "                        # before binning, make gdd & edd constrained to this same region\n",
    "                        try:\n",
    "                            \n",
    "                            edd_future_regrid_mask = edd_future_regrid.where(~np.isnan(ds_soilpyWBM_initial_chunk_single_year.isel(time=0).soilMoist))\n",
    "                            gdd_future_regrid_mask = gdd_future_regrid.where(~np.isnan(ds_soilpyWBM_initial_chunk_single_year.isel(time=0).soilMoist))\n",
    "                            deviation_from_normal_dr = deviation_from_normal.soilMoist  # now an xarray.DataArray\n",
    "                            deviation_from_normal_dr = deviation_from_normal_dr.assign_coords(\n",
    "                                time=pd.to_datetime(deviation_from_normal_dr.time.values.astype(str))\n",
    "                            )\n",
    "                            deviation_from_normal_dr = deviation_from_normal_dr.transpose('lat', 'lon', 'time')\n",
    "                            edd_future_regrid_mask   = edd_future_regrid_mask.transpose('lat', 'lon', 'time')\n",
    "                            \n",
    "                            deviation_from_normal_allign, edd_future_aligned = xr.align(\n",
    "                                deviation_from_normal_dr, edd_future_regrid_mask, join='left'\n",
    "                            )\n",
    "                            \n",
    "                            ds_bin_plus75 = xr.where(deviation_from_normal_allign >= 75, edd_future_aligned, 0)\n",
    "                            # now bin everything and save appropriately. keep it all in memory, avoid saving intermediary steps\n",
    "                            ds_bin_plus25_75   = xr.where((deviation_from_normal_allign < 75) & (deviation_from_normal_allign > 25), edd_future_aligned, 0)\n",
    "                            ds_bin_minus25_plus25 = xr.where((deviation_from_normal_allign <= 25) & (deviation_from_normal_allign >= -25), edd_future_aligned, 0)\n",
    "                            ds_bin_minus25_75  = xr.where((deviation_from_normal_allign > -75) & (deviation_from_normal_allign < -25), edd_future_aligned, 0)\n",
    "                            ds_bin_minus75     = xr.where(deviation_from_normal_allign <= -75, edd_future_aligned, 0)\n",
    "                            \n",
    "                            # Sum edd over the season (time dimension)\n",
    "                            combined_dataset_bins = xr.Dataset({\n",
    "                                \"gdd\":              gdd_future_regrid_mask,\n",
    "                                \"edd_plus75\":       ds_bin_plus75.sum(dim='time'),\n",
    "                                \"edd_plus25_75\":    ds_bin_plus25_75.sum(dim='time'),\n",
    "                                \"edd_minus25_plus25\": ds_bin_minus25_plus25.sum(dim='time'),\n",
    "                                \"edd_minus25_75\":   ds_bin_minus25_75.sum(dim='time'),\n",
    "                                \"edd_minus75\":      ds_bin_minus75.sum(dim='time')\n",
    "                            })\n",
    "                            \n",
    "                            results_season_and_soilm.append(combined_dataset_bins)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                                print(f\"{year} year error, pass this year\", e)\n",
    "                    \n",
    "                    ds_all_seasons = xr.concat(results_season_and_soilm, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06740d36-c0cc-4beb-9d4c-6032ad7aa373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x15216ceeae60> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    }
   ],
   "source": [
    "keys_single_place = list(combined_dataset_bins.keys())\n",
    "for key_i in keys_single_place:\n",
    "    print(key_i)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title(f\"{key_i} {year} {model_name_i} {initialization_i} ssp{ssp_i} {time_frame_i}\", fontsize=14)\n",
    "    data = combined_dataset_bins.isel(year=0)[key_i].compute()\n",
    "    data.plot()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1730d-0d0d-44c3-85ae-8da2fdf2d542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42db57-afe3-4c15-857e-4a8ab44ce1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
