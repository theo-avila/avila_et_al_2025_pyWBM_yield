2025-03-14 22:40:23,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.8.31:36121'
2025-03-14 22:40:24,046 - distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cta5244/dask-workers/dask-scratch-space/worker-6f3th7nd', purging
2025-03-14 22:40:25,672 - distributed.worker - INFO -       Start worker at:      tcp://10.6.8.31:41763
2025-03-14 22:40:25,672 - distributed.worker - INFO -          Listening to:      tcp://10.6.8.31:41763
2025-03-14 22:40:25,672 - distributed.worker - INFO -           Worker name:             SLURMCluster-3
2025-03-14 22:40:25,672 - distributed.worker - INFO -          dashboard at:            10.6.8.31:41833
2025-03-14 22:40:25,672 - distributed.worker - INFO - Waiting to connect to: tcp://146.186.150.11:36245
2025-03-14 22:40:25,672 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:40:25,672 - distributed.worker - INFO -               Threads:                          1
2025-03-14 22:40:25,673 - distributed.worker - INFO -                Memory:                   4.00 GiB
2025-03-14 22:40:25,673 - distributed.worker - INFO -       Local Directory: /scratch/cta5244/dask-workers/dask-scratch-space/worker-kstpuk5n
2025-03-14 22:40:25,673 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:40:26,251 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-14 22:40:26,251 - distributed.worker - INFO -         Registered to: tcp://146.186.150.11:36245
2025-03-14 22:40:26,251 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:40:26,251 - distributed.core - INFO - Starting established connection to tcp://146.186.150.11:36245
2025-03-14 22:41:07,804 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.8.39:37099
Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/worker.py", line 2075, in gather_dep
    response = await get_data_from_worker(
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/worker.py", line 2881, in get_data_from_worker
    response = await send_recv(
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.8.31:54016 remote=tcp://10.6.8.39:37099>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-03-14 22:41:09,437 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.8.26:39699
Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/worker.py", line 2075, in gather_dep
    response = await get_data_from_worker(
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/worker.py", line 2881, in get_data_from_worker
    response = await send_recv(
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.8.31:52588 remote=tcp://10.6.8.26:39699>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-03-14 22:42:05,689 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.8.13:36373
Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/worker.py", line 2075, in gather_dep
    response = await get_data_from_worker(
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/worker.py", line 2878, in get_data_from_worker
    comm = await rpc.connect(worker)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/core.py", line 1539, in connect
    return connect_attempt.result()
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.8.31:37490 remote=tcp://10.6.8.13:36373>: ConnectionResetError: [Errno 104] Connection reset by peer
Type = File(72057594037928473) name='/'Type = File(72057594037928474) name='/'Type = File(72057594037928475) name='/'Type = File(72057594037928476) name='/'Type = File(72057594037928481) name='/'Type = File(72057594037928482) name='/'Type = File(72057594037928483) name='/'Type = File(72057594037928484) name='/'Type = File(72057594037928485) name='/'Type = File(72057594037928486) name='/'Type = File(72057594037928487) name='/'Type = File(72057594037928488) name='/'Type = File(72057594037928489) name='/'Type = File(72057594037928490) name='/'Type = File(72057594037928491) name='/'Type = File(72057594037928492) name='/'Type = File(72057594037928493) name='/'Type = File(72057594037928494) name='/'Type = File(72057594037928495) name='/'Type = File(72057594037928496) name='/'Type = File(72057594037928497) name='/'Type = File(72057594037928498) name='/'Type = File(72057594037928499) name='/'Type = File(72057594037928500) name='/'Type = File(72057594037928501) name='/'Type = File(72057594037928502) name='/'Type = File(72057594037928503) name='/'Type = File(72057594037928504) name='/'Type = File(72057594037928509) name='/'Type = File(72057594037928510) name='/'Type = File(72057594037928511) name='/'Type = File(72057594037928512) name='/'Type = File(72057594037928513) name='/'Type = File(72057594037928514) name='/'Type = File(72057594037928515) name='/'Type = File(72057594037928516) name='/'Type = File(72057594037928517) name='/'Type = File(72057594037928518) name='/'Type = File(72057594037928519) name='/'Type = File(72057594037928520) name='/'Type = File(72057594037928521) name='/'Type = File(72057594037928522) name='/'Type = File(72057594037928523) name='/'Type = File(72057594037928524) name='/'Type = File(72057594037928525) name='/'Type = File(72057594037928526) name='/'Type = File(72057594037928527) name='/'Type = File(72057594037928528) name='/'Type = File(72057594037928529) name='/'Type = File(72057594037928530) name='/'Type = File(72057594037928531) name='/'Type = File(72057594037928532) name='/'Type = File(72057594037928537) name='/'Type = File(72057594037928538) name='/'Type = File(72057594037928539) name='/'Type = File(72057594037928540) name='/'Type = File(72057594037928541) name='/'Type = File(72057594037928542) name='/'Type = File(72057594037928543) name='/'Type = File(72057594037928544) name='/'Type = File(72057594037928545) name='/'Type = File(72057594037928546) name='/'Type = File(72057594037928547) name='/'Type = File(72057594037928548) name='/'Type = File(72057594037928549) name='/'Type = File(72057594037928550) name='/'Type = File(72057594037928551) name='/'Type = File(72057594037928552) name='/'Type = File(72057594037928553) name='/'Type = File(72057594037928554) name='/'Type = File(72057594037928555) name='/'Type = File(72057594037928556) name='/'Type = File(72057594037928557) name='/'Type = File(72057594037928558) name='/'Type = File(72057594037928559) name='/'Type = File(72057594037928560) name='/'Type = File(72057594037928565) name='/'Type = File(72057594037928566) name='/'Type = File(72057594037928567) name='/'Type = File(72057594037928568) name='/'Type = File(72057594037928569) name='/'Type = File(72057594037928570) name='/'Type = File(72057594037928571) name='/'Type = File(72057594037928572) name='/'Type = File(72057594037928573) name='/'Type = File(72057594037928574) name='/'Type = File(72057594037928575) name='/'Type = File(72057594037928576) name='/'Type = File(72057594037928577) name='/'Type = File(72057594037928578) name='/'Type = File(72057594037928579) name='/'Type = File(72057594037928580) name='/'Type = File(72057594037928581) name='/'Type = File(72057594037928582) name='/'Type = File(72057594037928583) name='/'Type = File(72057594037928584) name='/'Type = File(72057594037928585) name='/'Type = File(72057594037928586) name='/'Type = File(72057594037928587) name='/'Type = File(72057594037928588) name='/'Type = File(72057594037928596) name='/'Type = File(72057594037928597) name='/'Type = File(72057594037928598) name='/'Type = File(72057594037928599) name='/'Type = File(72057594037928600) name='/'Type = File(72057594037928601) name='/'Type = File(72057594037928602) name='/'Type = File(72057594037928603) name='/'Type = File(72057594037928604) name='/'Type = File(72057594037928605) name='/'Type = File(72057594037928606) name='/'Type = File(72057594037928607) name='/'Type = File(72057594037928608) name='/'Type = File(72057594037928609) name='/'Type = File(72057594037928610) name='/'Type = File(72057594037928611) name='/'Type = File(72057594037928612) name='/'Type = File(72057594037928613) name='/'Type = File(72057594037928614) name='/'Type = File(72057594037928615) name='/'Type = File(72057594037928616) name='/'Type = File(72057594037928617) name='/'Type = File(72057594037928618) name='/'Type = File(72057594037928619) name='/'2025-03-14 22:42:12,356 - distributed.nanny - INFO - Worker process 1601649 was killed by signal 11
2025-03-14 22:42:12,377 - distributed.nanny - WARNING - Restarting worker
2025-03-14 22:42:13,581 - distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cta5244/dask-workers/dask-scratch-space/worker-579eoihu', purging
2025-03-14 22:42:14,423 - distributed.worker - INFO -       Start worker at:      tcp://10.6.8.31:33051
2025-03-14 22:42:14,423 - distributed.worker - INFO -          Listening to:      tcp://10.6.8.31:33051
2025-03-14 22:42:14,423 - distributed.worker - INFO -           Worker name:             SLURMCluster-3
2025-03-14 22:42:14,423 - distributed.worker - INFO -          dashboard at:            10.6.8.31:43123
2025-03-14 22:42:14,423 - distributed.worker - INFO - Waiting to connect to: tcp://146.186.150.11:36245
2025-03-14 22:42:14,423 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:14,423 - distributed.worker - INFO -               Threads:                          1
2025-03-14 22:42:14,424 - distributed.worker - INFO -                Memory:                   4.00 GiB
2025-03-14 22:42:14,424 - distributed.worker - INFO -       Local Directory: /scratch/cta5244/dask-workers/dask-scratch-space/worker-wzzbix6d
2025-03-14 22:42:14,424 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:14,953 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-14 22:42:14,954 - distributed.worker - INFO -         Registered to: tcp://146.186.150.11:36245
2025-03-14 22:42:14,954 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:14,954 - distributed.core - INFO - Starting established connection to tcp://146.186.150.11:36245
Exception ignored in: <function CachingFileManager.__del__ at 0x14f003b92170>
Traceback (most recent call last):
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/xarray/backends/file_manager.py", line 250, in __del__
    self.close(needs_lock=False)
  File "/storage/home/cta5244/mambaforge/envs/pyWBM/lib/python3.10/site-packages/xarray/backends/file_manager.py", line 234, in close
    file.close()
  File "src/netCDF4/_netCDF4.pyx", line 2669, in netCDF4._netCDF4.Dataset.close
  File "src/netCDF4/_netCDF4.pyx", line 2636, in netCDF4._netCDF4.Dataset._close
  File "src/netCDF4/_netCDF4.pyx", line 2164, in netCDF4._netCDF4._ensure_nc_success
RuntimeError: NetCDF: HDF error
Type = File(72057594037927938) name='/'Type = File(72057594037927939) name='/'Type = File(72057594037927940) name='/'Type = File(72057594037927941) name='/'Type = File(72057594037927942) name='/'Type = File(72057594037927943) name='/'Type = File(72057594037927944) name='/'Type = File(72057594037927945) name='/'Type = File(72057594037927946) name='/'Type = File(72057594037927947) name='/'Type = File(72057594037927948) name='/'Type = File(72057594037927949) name='/'Type = File(72057594037927950) name='/'Type = File(72057594037927951) name='/'Type = File(72057594037927952) name='/'Type = File(72057594037927953) name='/'Type = File(72057594037927954) name='/'Type = File(72057594037927955) name='/'Type = File(72057594037927956) name='/'Type = File(72057594037927957) name='/'Type = File(72057594037927958) name='/'Type = File(72057594037927959) name='/'Type = File(72057594037927960) name='/'Type = File(72057594037927961) name='/'Type = File(72057594037927968) name='/'Type = File(72057594037927970) name='/'Type = File(72057594037927972) name='/'Type = File(72057594037927974) name='/'Type = File(72057594037927976) name='/'Type = File(72057594037927977) name='/'Type = File(72057594037927983) name='/'Type = File(72057594037927985) name='/'Type = File(72057594037927986) name='/'2025-03-14 22:42:22,666 - distributed.nanny - INFO - Worker process 1602062 was killed by signal 11
2025-03-14 22:42:22,670 - distributed.nanny - WARNING - Restarting worker
2025-03-14 22:42:23,516 - distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cta5244/dask-workers/dask-scratch-space/worker-oz492htv', purging
2025-03-14 22:42:24,300 - distributed.worker - INFO -       Start worker at:      tcp://10.6.8.31:34243
2025-03-14 22:42:24,300 - distributed.worker - INFO -          Listening to:      tcp://10.6.8.31:34243
2025-03-14 22:42:24,300 - distributed.worker - INFO -           Worker name:             SLURMCluster-3
2025-03-14 22:42:24,300 - distributed.worker - INFO -          dashboard at:            10.6.8.31:32959
2025-03-14 22:42:24,300 - distributed.worker - INFO - Waiting to connect to: tcp://146.186.150.11:36245
2025-03-14 22:42:24,300 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:24,300 - distributed.worker - INFO -               Threads:                          1
2025-03-14 22:42:24,300 - distributed.worker - INFO -                Memory:                   4.00 GiB
2025-03-14 22:42:24,300 - distributed.worker - INFO -       Local Directory: /scratch/cta5244/dask-workers/dask-scratch-space/worker-4uju4s2w
2025-03-14 22:42:24,300 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:24,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-14 22:42:24,716 - distributed.worker - INFO -         Registered to: tcp://146.186.150.11:36245
2025-03-14 22:42:24,716 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:24,716 - distributed.core - INFO - Starting established connection to tcp://146.186.150.11:36245
malloc_consolidate(): unaligned fastbin chunk detected
2025-03-14 22:42:29,948 - distributed.nanny - INFO - Worker process 1602119 was killed by signal 6
2025-03-14 22:42:29,952 - distributed.nanny - WARNING - Restarting worker
2025-03-14 22:42:30,882 - distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cta5244/dask-workers/dask-scratch-space/worker-1xrfy5yg', purging
2025-03-14 22:42:31,590 - distributed.worker - INFO -       Start worker at:      tcp://10.6.8.31:33005
2025-03-14 22:42:31,590 - distributed.worker - INFO -          Listening to:      tcp://10.6.8.31:33005
2025-03-14 22:42:31,590 - distributed.worker - INFO -           Worker name:             SLURMCluster-3
2025-03-14 22:42:31,590 - distributed.worker - INFO -          dashboard at:            10.6.8.31:37611
2025-03-14 22:42:31,590 - distributed.worker - INFO - Waiting to connect to: tcp://146.186.150.11:36245
2025-03-14 22:42:31,590 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:31,590 - distributed.worker - INFO -               Threads:                          1
2025-03-14 22:42:31,591 - distributed.worker - INFO -                Memory:                   4.00 GiB
2025-03-14 22:42:31,591 - distributed.worker - INFO -       Local Directory: /scratch/cta5244/dask-workers/dask-scratch-space/worker-f9l6zrd4
2025-03-14 22:42:31,591 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:32,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-14 22:42:32,362 - distributed.worker - INFO -         Registered to: tcp://146.186.150.11:36245
2025-03-14 22:42:32,362 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:32,362 - distributed.core - INFO - Starting established connection to tcp://146.186.150.11:36245
2025-03-14 22:42:39,070 - distributed.nanny - INFO - Worker process 1602242 was killed by signal 11
2025-03-14 22:42:39,073 - distributed.nanny - WARNING - Restarting worker
2025-03-14 22:42:40,148 - distributed.diskutils - INFO - Found stale lock file and directory '/scratch/cta5244/dask-workers/dask-scratch-space/worker-5dky1lpc', purging
2025-03-14 22:42:40,917 - distributed.worker - INFO -       Start worker at:      tcp://10.6.8.31:34329
2025-03-14 22:42:40,917 - distributed.worker - INFO -          Listening to:      tcp://10.6.8.31:34329
2025-03-14 22:42:40,917 - distributed.worker - INFO -           Worker name:             SLURMCluster-3
2025-03-14 22:42:40,918 - distributed.worker - INFO -          dashboard at:            10.6.8.31:37303
2025-03-14 22:42:40,918 - distributed.worker - INFO - Waiting to connect to: tcp://146.186.150.11:36245
2025-03-14 22:42:40,918 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:40,918 - distributed.worker - INFO -               Threads:                          1
2025-03-14 22:42:40,918 - distributed.worker - INFO -                Memory:                   4.00 GiB
2025-03-14 22:42:40,918 - distributed.worker - INFO -       Local Directory: /scratch/cta5244/dask-workers/dask-scratch-space/worker-souo_sig
2025-03-14 22:42:40,918 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:41,339 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-03-14 22:42:41,340 - distributed.worker - INFO -         Registered to: tcp://146.186.150.11:36245
2025-03-14 22:42:41,340 - distributed.worker - INFO - -------------------------------------------------
2025-03-14 22:42:41,340 - distributed.core - INFO - Starting established connection to tcp://146.186.150.11:36245
slurmstepd: error: *** JOB 35099577 ON p-bc-5021 CANCELLED AT 2025-03-14T22:42:44 ***
